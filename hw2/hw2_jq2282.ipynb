{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run hw2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Imports - our files\n",
    "import utils\n",
    "import models\n",
    "\n",
    "# Global definitions - data\n",
    "DATA_FN = 'data/crowdflower_data.csv'\n",
    "LABEL_NAMES = [\"happiness\", \"worry\", \"neutral\", \"sadness\"]\n",
    "\n",
    "# Global definitions - architecture\n",
    "EMBEDDING_DIM = 100  # We will use pretrained 100-dimensional GloVe\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "USE_CUDA = torch.cuda.is_available()  # CUDA will be available if you are using the GPU image for this homework\n",
    "\n",
    "# Global definitions - saving and loading data\n",
    "FRESH_START = True  # set this to false after running once with True to just load your preprocessed data from file\n",
    "#                     (good for debugging)\n",
    "TEMP_FILE = \"temporary_data.pkl\"  # if you set FRESH_START to false, the program will look here for your data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DataLoaders and embeddings from file....\n"
     ]
    }
   ],
   "source": [
    "# load the data and embeddings from file\n",
    "try:\n",
    "    with open(TEMP_FILE, \"rb\") as f:\n",
    "        print(\"Loading DataLoaders and embeddings from file....\")\n",
    "        train_generator, dev_generator, test_generator, embeddings, train_data = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"You need to have saved your data with FRESH_START=True once in order to load it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 91, 100])\n",
      "torch.Size([128, 100])\n"
     ]
    }
   ],
   "source": [
    "# test embeddings\n",
    "# ebs = nn.Embedding.from_pretrained(embeddings)\n",
    "# train1 = ebs(train_batch)\n",
    "# print(np.shape(train1))\n",
    "# train11 = torch.sum(train1,dim=1)\n",
    "# print(np.shape(train11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNetwork(\n",
      "  (embedding): Embedding(17635, 100)\n",
      "  (dense1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (dense2): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DenseNetwork(nn.Module):\n",
    "    def __init__(self, embed_dim, output_dim, hidden_dim, weight):\n",
    "        super(DenseNetwork, self).__init__()\n",
    "\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # TODO: Here, create any layers and attributes your network needs.\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        self.dense1 = nn.Linear(embed_dim, hidden_dim) \n",
    "        self.dense2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()     \n",
    "\n",
    "    def forward(self, x):\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # TODO: Fill in the forward pass of your neural network.\n",
    "        # TODO: (The backward pass will be performed by PyTorch magic for you!)\n",
    "        # TODO: Your architecture should...\n",
    "        # TODO: 1) Put the words through an Embedding layer (which was initialized with the pretrained embeddings);\n",
    "        x = self.embedding(x)\n",
    "        # TODO: 2) Take the sum of all word embeddings in a sentence\n",
    "        x = torch.sum(x,dim=1).float()\n",
    "        # TODO: 3) Feed the result into 2-layer feedforward network which produces a 4-vector of values,\n",
    "        # TODO: one for each class\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "        \n",
    "net = DenseNetwork(EMBEDDING_DIM, NUM_CLASSES, 64, embeddings)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(net(train_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(27.9350, grad_fn=<AddBackward0>)\n",
      "1 tensor(27.3739, grad_fn=<AddBackward0>)\n",
      "2 tensor(27.0554, grad_fn=<AddBackward0>)\n",
      "3 tensor(26.8350, grad_fn=<AddBackward0>)\n",
      "4 tensor(26.5253, grad_fn=<AddBackward0>)\n",
      "5 tensor(25.8699, grad_fn=<AddBackward0>)\n",
      "6 tensor(25.6448, grad_fn=<AddBackward0>)\n",
      "7 tensor(25.5283, grad_fn=<AddBackward0>)\n",
      "8 tensor(25.5029, grad_fn=<AddBackward0>)\n",
      "9 tensor(25.4591, grad_fn=<AddBackward0>)\n",
      "10 tensor(25.4942, grad_fn=<AddBackward0>)\n",
      "11 tensor(25.4476, grad_fn=<AddBackward0>)\n",
      "12 tensor(25.4547, grad_fn=<AddBackward0>)\n",
      "13 tensor(25.4571, grad_fn=<AddBackward0>)\n",
      "14 tensor(25.4687, grad_fn=<AddBackward0>)\n",
      "15 tensor(25.4762, grad_fn=<AddBackward0>)\n",
      "16 tensor(25.4888, grad_fn=<AddBackward0>)\n",
      "17 tensor(25.4845, grad_fn=<AddBackward0>)\n",
      "18 tensor(25.6559, grad_fn=<AddBackward0>)\n",
      "19 tensor(25.6036, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-e178bbf84c5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "model = DenseNetwork(EMBEDDING_DIM, NUM_CLASSES, HIDDEN_DIM, embeddings)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "  \n",
    "EPOCHS = 20\n",
    "losses = []\n",
    "for iepoch in range(EPOCHS): \n",
    "    for train_batch, train_label in train_generator:\n",
    "        # Compute and print loss\n",
    "        loss = criterion(model(train_batch),train_label)\n",
    "        #print(loss.item()) \n",
    "\n",
    "        # Zero the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss = 0\n",
    "    for ibatch, ilabel in dev_generator:\n",
    "        dev_loss = criterion(model(ibatch), ilabel)\n",
    "        total_loss += dev_loss\n",
    "    print(iepoch, total_loss)\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV9Z3/8dfnZiUkQCAQIAQjq0RAgnFFbV2winWd/qw6Y7G2UvvQPrS1nbHqtLYz7VjbcX7dZlqnWHV+ttWOaK3FBa21dUPCvsu+L4EEEiB7Pr8/7gEj3pA9J7n3/Xw87uOee5Z7P/dweN+T7/3e7zF3R0RE4lck7AJERKRrKehFROKcgl5EJM4p6EVE4pyCXkQkziWHXUAsOTk5XlBQEHYZIiK9xsKFC/e5++BYy3pk0BcUFFBSUhJ2GSIivYaZbWluWYtNN2aWb2ZvmNkqM1tpZncF86eY2XtmtsTMSszszGa2n2lm64LbzPa/DRERaY/WnNHXA/e4+yIzywIWmtk84GHgO+7+kpnNCB5/sumGZjYQ+DZQDHiw7QvuXt6Zb0JERJrX4hm9u+9y90XBdCWwGsgjGtz9gtX6AztjbP4pYJ67lwXhPg+4rDMKFxGR1mlTG72ZFQBFwHzgbuAVM/sR0Q+Mc2Nskgdsa/J4ezAv1nPPAmYBjBw5si1liYjICbS6e6WZZQLPAne7ewXwZeCr7p4PfBWY3ZFC3P1Rdy929+LBg2N+cSwiIu3QqqA3sxSiIf+Uu88JZs8Ejk7/Hoj1ZewOIL/J4xHBPBER6Sat6XVjRM/WV7v7I00W7QQ+EUxfBKyLsfkrwKVmlm1m2cClwTwREekmrWmjnwbcDCw3syXBvPuA24Afm1kyUE3Qvm5mxcDt7v5Fdy8zs38BFgTbfdfdyzr1HQSq6xr4n3e3cOrwfpw7JqcrXkJEpFdqMejd/S3Amll8eoz1S4AvNnn8GPBYewtsreSI8ejfNjJ15AAFvYhIE3Ez1k1yUoQrJw/njTWlHDhSG3Y5IiI9RtwEPcC1RXnUNjQyd/nusEsREekx4iroJ+b1Y/Tgvjy/WB17RESOiqugNzOuLcrj/c1lbCs7EnY5IiI9QlwFPcDVU6I/vH1haawRGUREEk/cBX3+wAzOKMhmzqLtuHvY5YiIhC7ugh7gmqI8NpQeZuXOirBLEREJXVwG/RWThpGSZDynL2VFROIz6AdkpHLh+CG8sHQn9Q2NYZcjIhKquAx6iPapL62s4Z0N+8MuRUQkVHEb9BeeMoSs9GT1qReRhBe3QZ+eksQVk4bx8srdHKmtD7scEZHQxG3QQ7T3zZHaBuat2hN2KSIioYnroD+zYCDD+6er942IJLS4DvpIxLi6KI+/rdtHaWVN2OWIiIQiroMeor1vGhqdF5dpSAQRSUxxH/TjcrMoHNZPvW9EJGHFfdBD9Kx+6faDbCg9FHYpIiLdLiGC/qopwzGDP+isXkQSUEIEfW6/dKaNzuG5JTs0oqWIJJyECHqI9qnfVlbFoq3lYZciItKtEiboP3VqLukpEfWpF5GEkzBBn5WewvTCoby4bBe19RrRUkQSR8IEPcC1RcM5cKSONz8oDbsUEZFuk1BBf/7YwQzsm6o+9SKSUBIq6FOSIlw5eRjzVu+horou7HJERLpFQgU9RHvf1NY38vLy3WGXIiLSLRIu6KfkD6BgUIZ634hIwki4oDczrinK471N+9l5oCrsckREulzCBT3ANVPycIcXlmpESxGJfwkZ9AU5fSkaOUC9b0QkIbQY9GaWb2ZvmNkqM1tpZncF8582syXBbbOZLWlm+81mtjxYr6Sz30B7XVuUx5rdlazeVRF2KSIiXao1Z/T1wD3uXgicDdxhZoXu/ll3n+LuU4BngTkneI4Lg3WLO6HmTnHFpGEkR4znl+isXkTiW4tB7+673H1RMF0JrAbyji43MwOuB37bVUV2hUGZaXxi3GD+sHgnjY0a0VJE4leb2ujNrAAoAuY3mX0+sMfd1zWzmQOvmtlCM5t1gueeZWYlZlZSWto9QxRcXZTH7opq3tu0v1teT0QkDK0OejPLJNpEc7e7N23YvpETn82f5+5TgcuJNvtcEGsld3/U3YvdvXjw4MGtLatDpk/IpW9qkr6UFZG41qqgN7MUoiH/lLvPaTI/GbgOeLq5bd19R3C/F3gOOLMjBXemPqlJXDZxGC8t3011XUPY5YiIdInW9LoxYDaw2t0fOW7xJcAad9/ezLZ9zSzr6DRwKbCiYyV3rmuL8qisqef11XvDLkVEpEu05ox+GnAzcFGT7pQzgmU3cFyzjZkNN7O5wcNc4C0zWwq8D/zJ3V/upNo7xTmjBzEkK01DIohI3EpuaQV3fwuwZpbdEmPeTmBGML0ROK1jJXatpIhx9ZTh/PrtzZQdrmVg39SwSxIR6VQJ+cvY411TlEd9o/On5bvCLkVEpNMp6IHCYf0Yl5up3jciEpcU9Hw4ouXCLeVs3X8k7HJERDqVgj5w9ZToj31/u2BryJWIiHQuBX0gb0AfrjxtOLP/tokNpYfCLkdEpNMo6Jv4509PID0lwjfnLNf4NyISNxT0TQzJSue+GRN4f1MZv1+4LexyREQ6hYL+ONcX53PmyQP53p9WU1pZE3Y5IiIdpqA/TiRifP/aSVTXNfLdF1eFXY6ISIcp6GMYMySTOy4cwx+X7uSNNRoDR0R6NwV9M27/5CjGDMnkgedXcLimPuxyRETaTUHfjLTkJP7tuknsOFDFf8z7IOxyRETaTUF/AmcUDOSms0by2NubWL79YNjliIi0i4K+Bf902SkMykzj3jnLqG9oDLscEZE2U9C3oH+fFL5z1ams3FnBr9/eHHY5IiJtpqBvhcsnDuWSCUN4ZN4HbCvToGci0rso6FvBzPju1ROJGDzw/ArcNTyCiPQeCvpWGj6gD1//1Hje/KCUF5buDLscEZFWU9C3wefOKeC0Ef357h9XceBIbdjliIi0ioK+DZIixr9dN5kDVXV8f+7qsMsREWkVBX0bFQ7vx23nj+KZku28s2Ff2OWIiLRIQd8Od108lpEDM7j/uRVU1zWEXY6IyAkp6NuhT2oS37t2Ipv2Hebnb6wPuxwRkRNS0LfT+WMHc11RHv/1lw2s3V0ZdjkiIs1S0HfA/VdMICs9mW/OWaZLD4pIj6Wg74BBmWk8cEUhi7Ye4Kn3t4ZdjohITAr6Drpuah7Txgzi4ZfWsPtgddjliIh8jIK+g8yM710zidqGRh58YWXY5YiIfIyCvhMU5PTlrkvG8vLK3by0fFfY5YiIfISCvpPcdv4oJuX152vPLGXx1vKwyxEROabFoDezfDN7w8xWmdlKM7srmP+0mS0JbpvNbEkz219mZmvNbL2Z3dvZb6CnSEmKMPuWYgZnpfH5xxewfq+6XIpIz9CaM/p64B53LwTOBu4ws0J3/6y7T3H3KcCzwJzjNzSzJODnwOVAIXCjmRV2Xvk9y5CsdP7nC2eSHIlw8+z32XmgKuySRERaDnp33+Xui4LpSmA1kHd0uZkZcD3w2xibnwmsd/eN7l4L/A64ujMK76lOGtSXJ249g0PV9dw8ez7lhzXKpYiEq01t9GZWABQB85vMPh/Y4+7rYmySB2xr8ng7TT4k4tWpw/vz3zOL2VZexecfX8DhmvqwSxKRBNbqoDezTKJNNHe7e0WTRTcS+2y+TcxslpmVmFlJaWlpR58udGePGsTPbixi2fYDfPmpRdTW68LiIhKOVgW9maUQDfmn3H1Ok/nJwHXA081sugPIb/J4RDDvY9z9UXcvdvfiwYMHt6asHu/SU4fy0HWT+esHpXz990s1TIKIhCK5pRWCNvjZwGp3f+S4xZcAa9x9ezObLwDGmtnJRAP+BuCmDtTb61x/Rj77D9fyg5fXMLBvKt++spDoLhUR6R6tOaOfBtwMXNSkO+WMYNkNHNdsY2bDzWwugLvXA3cCrxD9EvcZd0+4n4/e/olRfPG8k3n8nc0a1lhEul2LZ/Tu/hYQ8xTU3W+JMW8nMKPJ47nA3PaX2PuZGffNmEDZ4Vp+9OoHDOybxk1njQy7LBFJEC0GvXSOSMT4wWcmU36klgeeX052RgqXTxoWdlkikgA0BEI3SkmK8J9/fzpFI7O563dLeGe9rjkrIl1PQd/N+qQmMXtmMQU5Gdz2ZAnLtx8MuyQRiXMK+hAMyEjlyVvPYkBGKrf8+n027TscdkkiEscU9CEZ2j86Lo4DN8+ez54KXbRERLqGgj5EowZn8vjnz6D8cC2fm/0+B4/UhV2SiMQhBX3IJo8YwKOfK2bTvsN84YkFVNU2hF2SiMQZBX0PMG1MDv/x2Sks3FrO/c8tD7scEYkzCvoe4orJw/jKhWOYs3gHb6zZG3Y5IhJHFPQ9yB0XjWHskEzue245ldVqrxeRzqGg70HSkpN4+DOT2VNRzUMvrQm7HBGJEwr6HqZoZDa3TjuZp+Zv5d0N+8MuR0TigIK+B7rn0vGMHJjBN+csUy8cEekwBX0P1Cc1iYf+bhKb9x/hP177IOxyRKSXU9D3UOeOzuHGM/P51d82snTbgbDLEZFeTEHfg31zxgSGZKXzj/+7TNecFZF2U9D3YP3SU/jXayaydk8l//kXXZlKRNpHQd/DXVKYy1WnDefnb6xn7e7KsMsRkV5IQd8LfPvKQrLSU/jH/11KQ6OHXY6I9DIK+l5gUGYaD151Kku3H+SxtzaFXY6I9DIK+l7iysnDuGTCEH706lo260IlItIGCvpewsz412smkZoU4Z+eXUajmnBEpJUU9L3I0P7p3H/FBOZvKuO3C7aGXY6I9BIK+l7ms2fkc+7oQfzb3DXsOlgVdjki0gso6HsZM+Oh6yZT39jI/c+twF1NOCJyYgr6XmjkoAy+ful4/rxmL39YsjPsckSkh1PQ91Kfn3YyRSMH8J0/rmTfoZqwyxGRHkxB30slRYyH/24yh2saePCFlWGXIyI9mIK+Fxubm8WdF43hxWW7eHXl7rDLEZEeSkHfy335k6M5ZWgWDzy/goNVus6siHycgr6XS0mK8MPPnMa+QzV8/0+rwy5HRHqgFoPezPLN7A0zW2VmK83sribLvmJma4L5Dzez/WYzW25mS8yspDOLl6hJI/pz2wWjeLpkG2+v3xd2OSLSwyS3Yp164B53X2RmWcBCM5sH5AJXA6e5e42ZDTnBc1zo7kqgLvTVS8bx4tJd/OLNDUwbkxN2OSLSg7R4Ru/uu9x9UTBdCawG8oAvAw+5e02wbG9XFionlp6SxBWTh/Hexv1UVqutXkQ+1KY2ejMrAIqA+cA44Hwzm29mb5rZGc1s5sCrZrbQzGad4LlnmVmJmZWUlpa2pSwJTC/Mpa7BefMD7T8R+VCrg97MMoFngbvdvYJos89A4GzgG8AzZmYxNj3P3acClwN3mNkFsZ7f3R9192J3Lx48eHBb34cAU0dmM7BvKvNW7Qm7FBHpQVoV9GaWQjTkn3L3OcHs7cAcj3ofaAQ+1jjs7juC+73Ac8CZnVG4fFxSxLjolCG8sWYvdQ26mLiIRLWm140Bs4HV7v5Ik0XPAxcG64wDUoF9x23bN/gCFzPrC1wKrOic0iWW6YW5VFTXs2BTWdiliEgP0Zoz+mnAzcBFQRfJJWY2A3gMGGVmK4DfATPd3c1suJnNDbbNBd4ys6XA+8Cf3P3lLngfEjh/bA5pyRFeVfONiARa7F7p7m8BsdreAf4hxvo7gRnB9EbgtI4UKG2TkZrM+WNzmLdqD9++spDYX5uISCLRL2Pj0CUTctlxoIrVuyrDLkVEegAFfRy6eEIuZvDaajXfiIiCPi4NzkqjKH+AulmKCKCgj1vTC4eyfMdBXVdWRBT08Wp6YXToodd0Vi+S8BT0cWr04ExOzunLvNUagkgk0Sno45SZMb0wl3c37NMgZyIJTkEfxy6ZoEHORERBH9dOP0mDnImIgj6uaZAzEQEFfdzTIGcioqCPcxrkTEQU9HEuIzWZ88ZEBzlz97DLEZEQKOgTwPTC6CBna3ZrkDORRKSgTwBHBzlT7xuRxKSgTwCDs9KYokHORBKWgj5BTC/M1SBnIglKQZ8gLi3MBeA1jX0jknAU9Ani2CBnar4RSTgK+gRhZlwyYYgGORNJQAr6BDK9cKgGORNJQAr6BHL6SdlkZ6ToYiQiCUZBn0Cig5zl8mcNciaSUBT0CUaDnIkkHgV9grlgnAY5E0k0CvoEc3SQs9dWa5AzkUShoE9AlxTmsr1cg5yJJAoFfQK6eMIQDXImkkAU9AloSFa6BjkTSSAK+gSlQc5EEoeCPkFNn6BBzkQSRYtBb2b5ZvaGma0ys5VmdleTZV8xszXB/Ieb2f4yM1trZuvN7N7OLF7ab8yQTAoGZaj5RiQBJLdinXrgHndfZGZZwEIzmwfkAlcDp7l7jZkNOX5DM0sCfg5MB7YDC8zsBXdf1XlvQdrDzJhemMvj72ymsrqOrPSUsEsSkS7S4hm9u+9y90XBdCWwGsgDvgw85O41wbJYbQBnAuvdfaO71wK/I/rhID2ABjkTSQxtaqM3swKgCJgPjAPON7P5ZvammZ0RY5M8YFuTx9uDebGee5aZlZhZSWmpgqc7TB05QIOciSSAVge9mWUCzwJ3u3sF0WafgcDZwDeAZ8zM2luIuz/q7sXuXjx48OD2Po20QXJSRIOciSSAVgW9maUQDfmn3H1OMHs7MMej3gcagZzjNt0B5Dd5PCKYJz2EBjkTiX+t6XVjwGxgtbs/0mTR88CFwTrjgFRg33GbLwDGmtnJZpYK3AC80BmFS+e4YFwOqRrkTCSuteaMfhpwM3CRmS0JbjOAx4BRZraC6JesM93dzWy4mc0FcPd64E7gFaJf4j7j7iu75J1Iu2iQM5H412L3Snd/C2iu7f0fYqy/E5jR5PFcYG57C5SuN70w2k6/ZnclE4b1C7scEelk+mWscPGE6E8g9OMpkfikoBcNciYS5xT0AmiQM5F4pqAXAC4t1CBnIvFKQS9AdJCzcbmZ/OT1dWwrOxJ2OSLSiRT0AkQHOfvZTVOpqWtg5q/fp/xwbdgliUgnUdDLMeNys5h9yxlsL6/i1icWUFXbEHZJItIJFPTyEWcUDOQnN0xhybYD3PmbRdRrDByRXk9BLx9z2cRhfPeqU3l9zV4eeH6FfjEr0su15sIjkoBuPqeAPRU1/OyN9eT2S+er08eFXZKItJOCXpp1z6Xj2FNRzY9fX0duv3RuOmtk2CWJSDso6KVZZsb3r5tE6aEaHnh+OYOz0pge9LcXkd5DbfRyQilJEf7z76cyKa8/d/5mEQu3aNx6kd5GQS8tykhN5rFbzmBY/3S+8EQJ6/ceCrskEWkDBb20yqDMNJ689SySI8bMx95nT0V12CWJSCsp6KXVRg7K4Ne3nMmBI7XMfOx9Kqrrwi5JRFpBQS9tMmlEf35x8+ms33uILz25kJp6/XpWpKdT0EubnT92MD/8P5N5d+N+7nlmKY2N+kGVSE+m7pXSLtcWjWBPRQ0PvbSGIVnp/POnJxC9jryI9DQKemm3L10wit0Hq3ns7U0M7Z/GrAtGh12SiMSgoJd2MzO+9elCSitr+P7c6Jn9NUV5YZclEoqdB6pYu7uSqSOz6Z+REnY5H6Gglw6JRIx/v/409h+u4Rv/u5T0lCQumzg07LJEutW7G/Zz+/9byMGqOiIGE/P6c87oQUwbnUNxQTYZqeFGrfXEkQmLi4u9pKQk7DKkDSqq67jx0fdYubOCi08ZwgOfLuTknL5hlyXS5Z4p2cZ9c5ZTkNOXb15+Cst3HOSdDftZvLWcugYnJckoys/m3DGDOHd0DlPyB5Ca3Pn9YMxsobsXx1ymoJfOUlPfwONvb+anf15PTX0Dn592MndeNIZ+6T3rz1iRztDY6Pzw1bX81182cP7YHH5201T69/nwWK+qbWDB5jLe2bCfdzfsY/mOgzQ69ElJ4oyTB3Lu6EGcO3oQpw7vT1Kk4x0ZFPTSrfZWVvOjV9by+4XbGdQ3lW98ajyfOT2/Uw5mkZ6gqraBrz2zhJdW7Oams0bynatOJSXpxGfpB6vqmL9xP+9s2M87G/bxwZ7oUCL90pM5e1Q09KeNyWHMkMx29WBT0Esolm0/wHf+uIqFW8qZmNePb195KmcUDAy7LJEO2VtRzW1PlrBsx0HunzGBL5x3cruCubSyhnc37ued9ft4Z8N+tpYdoX+fFBb/83Qi7TgpUtBLaNydF5bu5KGX1rDrYDVXnTacey8/heED+oRdmkibrdpZwRefWMCBqjp+fENRpw7bva3sCFvLjjBtTE67tlfQS+iO1Nbzizc38ss3N2AGt39iNF+6YDR9UpPCLk2kVf68Zg9f+c1istJT+NXMYibm9Q+7pI84UdBrCATpFhmpyXxt+jhev+cTXDwhl//72jou/ve/8MelO3VNWunxHn97E198ooSCnL48f8e0HhfyLVHQS7cakZ3Bz2+aytOzzmZARipf+e1irv/lu6zYcTDs0kQ+pr6hkW/9YQUP/nEVF0/I5fe3n8PQ/ulhl9VmarqR0DQ0Os+UbONHr6yl7Egtny3O53PnFDByUAaZafotn4SrsrqOO3+zmDc/KGXWBaP4p8tO6dE9xzrURm9m+cCTQC7gwKPu/mMzexC4DSgNVr3P3efG2H4zUAk0APXNFdKUgj6xHKyq46evr+PxdzZTH4yEOSAjhfzsDEZk9wlu0en8gRnkDehDX30QSBfaXn6ELzxewobSQ/zLNRO58cyRYZfUoo4G/TBgmLsvMrMsYCFwDXA9cMjdf9TC9puBYnff19qCFfSJaVvZEZZuP8D28iq2lR1he3kV28uj9zX1jR9Zd2Df1GMfAh9+IGQwZkgmI7L7aCRNabfFW8u57ckSauob+cU/nN7uXjDd7URB3+JpkbvvAnYF05VmthrQyFXS6fIHZpA/MONj892d0kM1QfB/GP7byo6wZlclr63eS22TD4KczDSm5A+gaGT0NnnEgC5rCnJ3dh6s5oPdlazdU0lqUoTTT8qmcHi/Fn9AI52nodE5VF1PTX0DKUkRkpOMlKQIKUmRNjW3vLhsJ/c8s5Tcfun8blYxY4ZkdWHV3adNbfRmVgD8FZgIfA24BagASoB73L08xjabgHKizT6/dPdHm3nuWcAsgJEjR56+ZcuWNrwNSWSNjc6+QzVsKz/Cql2VLN5azpKtB9i47zAAEYNxuVnHwn9KfjZjhmS2ub21/HAta/dUsjYI9bW7K/lgdyWVNfUfW7dPShKn5fen+KSBnF6QHR3RsI+GgoilodGprmugqq6BIzUNVFTXUVFVF9zXN3lc/+H8YLry6H2Mf4OjzCAlEiElyUhOit4f+zCIRI5NJ0WMZdsPUnxSNr+8+XQGZaZ1417ouE7pR29mmcCbwPfcfY6Z5QL7iAb4vxBt3rk1xnZ57r7DzIYA84CvuPtfT/RaarqRznDgSC1Lth1g8dYDLNkWvR2sil7nNjMtmckj+kfP+vOzmTJyADnBf+yq2gbW7a1kTRDkR0N9b2XNseful57MKUP7MX5oFuOGZnHK0CzG5WZRVdtAyZYySjaXs3BLOat2VdDQ6JjB+NwsTj8pm+KCbIpPGtjrmpjqGhqprK7nUHU0fCur66msruNQTf2x6cO1DVTVNlBTH72vrmukqq6B6mO3Dx9X1TVQU9dIbUNji69tBllpyfTrk0K/9BT69UkO7j/6ODU5Qn1DI3UNTl1jI/UNTt3Rxw2N0WWNTl19I/WNR5dF16ttaGRcbhbf+NR40lN63+87Ohz0ZpYCvAi84u6PxFheALzo7hNbeJ4HaUW7voJeukJjo7Np/2GWbD3A4m3lLNl2gNW7KmkIvgDOH9iHJDO2lB3h6H+LtOQIY3MzGZ/bj/FDMxk/tB/jc7PI7ZfWqpA+XFPP0m0HWLC5nJItZSzeeoBDwdnnkKy0Y6FfXJDNhGEfb+5xjwZQdV0jNUFQVtd/GJrHArQ+uryuwWlobKSh0Wnw6HtucKeh0Y9NfzgPGoNlDY1Oo0fPrKOhXU9lTTS8j4Z4dV3LgZyaFCE9JUJ6ShJ9UpNIT04iPTWJ9ORgXkoS6SkR+qQmkZb84Tp9UqPLM1KT6d8nhaz05A8DvE8KmanJ7RoWIJF09MtYA54Aytz97ibzhwXt95jZV4Gz3P2G47btC0SCtv2+RM/ov+vuL5/oNRX00l2qahtYvuMgS4Lgd4fxQ7MYn5vF+KFZnDSob6d2qWtodNburmThljJKtpRTsrmcHQeqgGhzT26/tGNhXhPcd0UP6KSIkWRGJEJwH226SEuOkJUeDdqj9/2C6cy05I/MPxrGWenJwbKULhl+V1qno0F/HvA3YDlw9CP9PuBGYArRppvNwJfcfZeZDQd+5e4zzGwU8FywTTLwG3f/XksFK+glkew6WHWsqafscO2xM+L0lOiZcFpKEmnJTealRKJnykenmyxPSYoQiUByJPJhkEeMiFmTcNeZcTzSWDciInFOY92IiCQwBb2ISJxT0IuIxDkFvYhInFPQi4jEOQW9iEicU9CLiMQ5Bb2ISJzrkT+YMrNSoKcOX5lDdDC3nkr1dYzq6xjV1zEdqe8kdx8ca0GPDPqezMxKWnOVrLCovo5RfR2j+jqmq+pT042ISJxT0IuIxDkFfdvFvEJWD6L6Okb1dYzq65guqU9t9CIicU5n9CIicU5BLyIS5xT0MZhZvpm9YWarzGylmd0VY51PmtlBM1sS3L7VzTVuNrPlwWt/7CotFvUTM1tvZsvMbGo31ja+yX5ZYmYVZnb3cet06/4zs8fMbK+ZrWgyb6CZzTOzdcF9djPbzgzWWWdmM7uxvh+a2Zrg3+85MxvQzLYnPBa6sL4HzWxHk3/DGc1se5mZrQ2OxXu7sb6nm9S22cyWNLNtd+y/mJnSbcegu+t23A0YBkwNprOAD4DC49b5JNELoodV42Yg5wTLZwAvAQacDcwPqc4kYDfRH3OEtv+AC4CpwIom8x4G7g2m7wV+EGO7gcDG4D47mM7upvouBZKD6R/Eqq81x0IX1vcg8PVW/PtvAEYBqcDS4/8vdVV9xy3/d+BbIe6/mJnSXcegzuhjcPdd7qpLYVkAAAMqSURBVL4omK4EVgN54VbVZlcDT3rUe8AAMxsWQh0XAxvcPdRfOrv7X4Gy42ZfTfTC9wT318TY9FPAPHcvc/dyohe4v6w76nP3V929Pnj4HjCis1+3tZrZf61xJrDe3Te6ey3wO6L7vVOdqD4zM+B64Led/bqtdYJM6ZZjUEHfAjMrAIqA+TEWn2NmS83sJTM7tVsLi16U/VUzW2hms2IszwO2NXm8nXA+rG6g+f9gYe4/gFx33xVM7wZyY6zTU/bjrUT/QoulpWOhK90ZNC091kyzQ0/Yf+cDe9x9XTPLu3X/HZcp3XIMKuhPwMwygWeBu9294rjFi4g2R5wG/BR4vpvLO8/dpwKXA3eY2QXd/PotMrNU4Crg9zEWh73/PsKjfyP3yL7GZnY/UA881cwqYR0L/wWMBqYAu4g2j/REN3Lis/lu238nypSuPAYV9M0wsxSi/yBPufuc45e7e4W7Hwqm5wIpZpbTXfW5+47gfi/wHNE/kZvaAeQ3eTwimNedLgcWufue4xeEvf8Ce442ZwX3e2OsE+p+NLNbgE8Dfx8Ewce04ljoEu6+x90b3L0R+O9mXjfs/ZcMXAc83dw63bX/msmUbjkGFfQxBG16s4HV7v5IM+sMDdbDzM4kui/3d1N9fc0s6+g00S/tVhy32gvA54LeN2cDB5v8idhdmj2TCnP/NfECcLQHw0zgDzHWeQW41Myyg6aJS4N5Xc7MLgP+EbjK3Y80s05rjoWuqq/pdz7XNvO6C4CxZnZy8BfeDUT3e3e5BFjj7ttjLeyu/XeCTOmeY7Arv2nurTfgPKJ/Qi0DlgS3GcDtwO3BOncCK4n2IngPOLcb6xsVvO7SoIb7g/lN6zPg50R7PCwHirt5H/YlGtz9m8wLbf8R/cDZBdQRbeP8AjAIeB1YB7wGDAzWLQZ+1WTbW4H1we3z3VjfeqJts0ePwV8E6w4H5p7oWOim+v4nOLaWEQ2sYcfXFzyeQbSXyYburC+Y//jRY67JumHsv+YypVuOQQ2BICIS59R0IyIS5xT0IiJxTkEvIhLnFPQiInFOQS8iEucU9CIicU5BLyIS5/4/9Knvg4WAND8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1,EPOCHS+1)\n",
    "plt.plot(x, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17635, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x106df65f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, optimizer, train_generator, dev_generator):\n",
    "    \"\"\"\n",
    "    Perform the actual training of the model based on the train and dev sets.\n",
    "    :param model: one of your models, to be trained to perform 4-way emotion classification\n",
    "    :param loss_fn: a function that can calculate loss between the predicted and gold labels\n",
    "    :param optimizer: a created optimizer you will use to update your model weights\n",
    "    :param train_generator: a DataLoader that provides batches of the training set\n",
    "    :param dev_generator: a DataLoader that provides batches of the development set\n",
    "    :return model, the trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for epoch in range(50):\n",
    "        # Forward Propagation\n",
    "        y_pred = model(x)\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        print('epoch: ', epoch,' loss: ', loss.item())\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecurrentNetwork(\n",
      "  (embedding): Embedding(17635, 100)\n",
      "  (lstm): LSTM(100, 64, num_layers=2)\n",
      "  (linear): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd as autograd\n",
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, sentence_len, output_dim, hidden_dim, weight):\n",
    "        super(RecurrentNetwork, self).__init__()\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # TODO: Here, create any layers and attributes your network needs.\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_dim = np.shape(weight)[1]  \n",
    "        # Define hidden dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Define 2-layer LSTM\n",
    "        self.lstm = nn.LSTM(self.embed_dim, self.hidden_dim,num_layers=2) \n",
    "        #self.lstm2 = nn.LSTM(hidden_dim, output_dim)\n",
    "        # Define final transform layer\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU() \n",
    "\n",
    "        \n",
    "    # x is a PaddedSequence for an RNN\n",
    "    def forward(self, x):\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # TODO: 1) Put the words through an Embedding layer (which was initialized with the pretrained embeddings);\n",
    "        batch_size = np.shape(x)[0]\n",
    "        if np.shape(x)[1] != self.sentence_len:\n",
    "            x = self.pad(x)\n",
    "        mid = self.embedding(x).float()\n",
    "        # TODO: 2) Feed the sequence of embeddings through a 2-layer RNN\n",
    "        mid = mid.view(self.sentence_len, batch_size, -1)\n",
    "        # Add hidden layer\n",
    "        self.hidden = self.initialize_hidden(x)\n",
    "        out, _ = self.lstm(mid, self.hidden)\n",
    "        # TODO: 3) Feed the last output state into a dense layer to become a 4-vector of values, one for each class    \n",
    "        out = self.linear(out[-1].view(batch_size, -1))\n",
    "        return self.relu(out)\n",
    "        \n",
    "    def initialize_hidden(self,x):\n",
    "        # n_layers * n_directions, batch_size, rnn_hidden_size\n",
    "        batch_size = np.shape(x)[0]\n",
    "        return (autograd.Variable(torch.zeros(2, batch_size, self.hidden_dim)),\n",
    "               autograd.Variable(torch.zeros(2, batch_size, self.hidden_dim)))\n",
    "    \n",
    "    def pad(self, x):\n",
    "        if np.shape(x)[1] > self.sentence_len:\n",
    "            return x[:,:self.sentence_len]\n",
    "        elif np.shape(x)[1] < self.sentence_len:\n",
    "            tmp = torch.zeros(np.shape(x)[0], self.sentence_len-np.shape(x)[1], dtype=torch.long)\n",
    "            return torch.cat((x,tmp), 1)\n",
    "        \n",
    "net = RecurrentNetwork(91, NUM_CLASSES, 64, embeddings)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecurrentNetwork2(\n",
      "  (embedding): Embedding(17635, 100)\n",
      "  (lstm): LSTM(100, 64, num_layers=2)\n",
      "  (linear): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RecurrentNetwork2(nn.Module):\n",
    "    def __init__(self, sentence_len, output_dim, hidden_dim, weight):\n",
    "        super(RecurrentNetwork2, self).__init__()\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # TODO: Here, create any layers and attributes your network needs.\n",
    "        # Define dimensions\n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_dim = weight.size(1) \n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Define embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        # Define 2-layer LSTM\n",
    "        self.lstm = nn.LSTM(self.embed_dim, self.hidden_dim,num_layers=2) \n",
    "        # Define final dense layer\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    # x is a PaddedSequence for an RNN\n",
    "    def forward(self, x):\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # TODO: 1) Put the words through an Embedding layer (which was initialized with the pretrained embeddings);\n",
    "        batch_size = x.size(0)\n",
    "        if x.size(1) != self.sentence_len:\n",
    "            x = self.pad(x)\n",
    "        mid = self.embedding(x).float()\n",
    "        # TODO: 2) Feed the sequence of embeddings through a 2-layer RNN\n",
    "        out, _ = self.lstm(mid.view(self.sentence_len, batch_size, -1))\n",
    "        # TODO: 3) Feed the last output state into a dense layer to become a 4-vector of values, one for each class    \n",
    "        out = self.linear(out[-1].view(batch_size, -1))\n",
    "        return out\n",
    "    \n",
    "    def pad(self, x):\n",
    "        if x.size(1) > self.sentence_len:\n",
    "            return x[:,:self.sentence_len]\n",
    "        elif x.size(1) < self.sentence_len:\n",
    "            tmp = torch.zeros(x.size(0), self.sentence_len-x.size(1), dtype=torch.long)\n",
    "            return torch.cat((x,tmp), 1)\n",
    "        \n",
    "net = RecurrentNetwork2(91, NUM_CLASSES, 64, embeddings)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(29.9571, grad_fn=<AddBackward0>)\n",
      "1 tensor(29.9643, grad_fn=<AddBackward0>)\n",
      "2 tensor(29.9784, grad_fn=<AddBackward0>)\n",
      "3 tensor(30.0040, grad_fn=<AddBackward0>)\n",
      "4 tensor(30.0389, grad_fn=<AddBackward0>)\n",
      "5 tensor(30.0773, grad_fn=<AddBackward0>)\n",
      "6 tensor(30.1187, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-b64e330aa073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# perform a backward pass (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "SENTENCE_LEN = 91\n",
    "model3 = RecurrentNetwork2(SENTENCE_LEN, NUM_CLASSES, HIDDEN_DIM, embeddings)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters())\n",
    "  \n",
    "EPOCHS = 20\n",
    "losses = []\n",
    "for iepoch in range(EPOCHS): \n",
    "    for train_batch, train_label in train_generator:\n",
    "        # Compute and print loss\n",
    "        loss = criterion(model3(train_batch),train_label)\n",
    "        #print(loss.item()) \n",
    "\n",
    "        # Zero the gradients\n",
    "        model3.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss = 0\n",
    "    for ibatch, ilabel in dev_generator:\n",
    "        dev_loss = criterion(model3(ibatch), ilabel)\n",
    "        total_loss += dev_loss\n",
    "    print(iepoch, total_loss)\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: \n",
      "tensor([31.3124])\n",
      "F-score: \n",
      "0.241271458015108\n"
     ]
    }
   ],
   "source": [
    "test_model(model2, criterion, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: \n",
      "tensor([30.0885])\n",
      "F-score: \n",
      "0.20516519559165525\n"
     ]
    }
   ],
   "source": [
    "test_model(model3, criterion, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, len_seq = nn.utils.rnn.pad_packed_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(embeddings)\n",
    "x = embedding(ibatch).float()\n",
    "h0 = Variable(torch.zeros(2, x.size(0), 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(100, 64, 2, batch_first=True)\n",
    "out, _ = rnn(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 91, 64])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59, 82])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = torch.LongTensor([len(seq) for seq in ibatch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
       "        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
       "        82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82,\n",
       "        82, 82, 82, 82, 82])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 91])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-60b81ea1ad43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mseq_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "seq_tensor = torch.zeros((ibatch.size(0), 91))#.long().cuda()\n",
    "for idx, (seq, seqlen) in enumerate(zip(ibatch, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "print(np.shape(seq_tensor))\n",
    "embedding(seq_tensor).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 22])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ibatch == 0).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_seq =  torch.LongTensor([(seq==0).nonzero()[0] for seq in ibatch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 28, 20, 23, 32,  4, 15, 14, 15,  4, 17,  3,  5, 18, 16, 28, 21, 27,\n",
       "        20, 19, 24, 19, 30, 18,  6,  8, 16,  7,  7, 19, 22, 14, 15,  7, 31, 15,\n",
       "        20, 20, 23, 15, 17, 22, 14, 30,  9, 19, 19, 17, 21, 27, 12,  2, 20,  6,\n",
       "        12, 15, 18, 10,  7])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PackedSequence' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-16ede9dd8d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1896\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "nn.utils.rnn.pack_padded_sequence(ibatch,len_seq,batch_first=True,enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 59])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-32b3cdd30781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mseq_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mseq_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding.from_pretrained(embeddings)\n",
    "print(np.shape(seq_tensor))\n",
    "embedding = nn.Embedding.from_pretrained(embeddings)\n",
    "seq_tensor = embedding(seq_tensor).float()\n",
    "seq_tensor = seq_tensor.transpose(0,1)\n",
    "packed_input = pack_padded_sequence(seq_tensor, seq_lengths.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "iseq = nn.utils.rnn.pack_padded_sequence(ibatch,seq_lengths,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4838])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(iseq.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'batch_sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-8d70332e5a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_length\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'batch_sizes'"
     ]
    }
   ],
   "source": [
    "test,length = nn.utils.rnn.pad_packed_sequence(ibatch,batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pack_padded_sequence() missing 1 required positional argument: 'lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-b70b7d4efc02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: pack_padded_sequence() missing 1 required positional argument: 'lengths'"
     ]
    }
   ],
   "source": [
    "nn.utils.rnn.pack_padded_sequence(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_length = [ibatch.size(1)]*ibatch.size(0)\n",
    "ibatch = embedding(ibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, sentence_len):\n",
    "    if x.size(1) > sentence_len:\n",
    "        return x[:,:sentence_len,:].transpose(0,1)\n",
    "    elif x.size(1) < sentence_len:\n",
    "        padded_x = np.zeros((sentence_len,x.size(0),100))\n",
    "        \n",
    "        tmp = torch.zeros(x.size(0), sentence_len-x.size(1),100, dtype=torch.long)\n",
    "        print(tmp.size(),x.size())\n",
    "        return torch.cat((x.transpose(0,1),tmp.transpose(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([82, 59, 100])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.zeros(,ibatch.transpose(0,1)))\n",
    "ibatch.transpose(0,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 9, 100]) torch.Size([59, 82, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Double but got scalar type Long for sequence element 1 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-348-d7b4cf52c09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m91\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-347-158111a135f1>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(x, sentence_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Double but got scalar type Long for sequence element 1 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "mid = pad(ibatch,91)\n",
    "mid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (embedding): Embedding(17635, 100)\n",
      "  (rnn): RNN(100, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# different rnn\n",
    "from torch.autograd import Variable\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, sentence_len, output_dim,hidden_dim, layer_dim,weight):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_dim = weight.size(1) \n",
    "        \n",
    "        # Define embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(self.embed_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        #self.drop_layer = nn.Dropout(0.5)\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        if x.size(1) != self.sentence_len:\n",
    "            x_lengths, x = self.pad(x) \n",
    "            x = self.embedding(x).float()\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, x_lengths, batch_first=True)\n",
    "            # Initialize hidden state with zeros\n",
    "            #h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "\n",
    "            # One time step\n",
    "            out, _ = self.rnn(x)\n",
    "            #out = self.drop_layer(out)\n",
    "            print(np.shape(out))\n",
    "            out, _ = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "            print(np.shape(out))\n",
    "            out = out.contiguous()[:,-1,:]\n",
    "            print(np.shape(out))\n",
    "            out = self.fc(out)\n",
    "        else:\n",
    "            x = self.embedding(x).float()\n",
    "            out, _ = self.rnn(x)\n",
    "            out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "    def pad(self, x):\n",
    "        if x.size(1) > self.sentence_len:\n",
    "            return [len(ix) for ix in x], x[:,:self.sentence_len]\n",
    "        elif x.size(1) < self.sentence_len:\n",
    "            x_lengths = [len(ix) for ix in x]\n",
    "            padded_x = torch.zeros(x.size(0), self.sentence_len, dtype=torch.long)\n",
    "            # copy over the actual sequences\n",
    "            for i, x_len in enumerate(x_lengths):\n",
    "                sequence = x[i]\n",
    "                padded_x[i, 0:x_len] = sequence[:x_len]\n",
    "            return x_lengths, padded_x\n",
    "net = RNNModel(91, NUM_CLASSES, 64,2, embeddings)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39463210105896\n",
      "1.3888366222381592\n",
      "1.3748220205307007\n",
      "1.3817405700683594\n",
      "1.3644577264785767\n",
      "1.3414642810821533\n",
      "1.3237872123718262\n",
      "1.3141095638275146\n",
      "1.383470892906189\n",
      "1.396377682685852\n",
      "1.348715901374817\n",
      "(4,)\n",
      "torch.Size([128, 82, 100])\n",
      "torch.Size([128, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [128 x 100], m2: [64 x 4] at ../aten/src/TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-385-e54f241a7b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdev_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mdev_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdev_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-383-0b7b7599397e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 100], m2: [64 x 4] at ../aten/src/TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "SENTENCE_LEN = 91\n",
    "model3 = RNNModel(SENTENCE_LEN, NUM_CLASSES, HIDDEN_DIM,2, embeddings)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters())\n",
    "  \n",
    "EPOCHS = 20\n",
    "losses = []\n",
    "for iepoch in range(EPOCHS): \n",
    "    i = 0\n",
    "    for train_batch, train_label in train_generator:\n",
    "        if i>10:\n",
    "            break\n",
    "        i += 1\n",
    "        # Compute and print loss\n",
    "        loss = criterion(model3(train_batch),train_label)\n",
    "        print(loss.item()) \n",
    "\n",
    "        # Zero the gradients\n",
    "        model3.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss = 0\n",
    "    for ibatch, ilabel in dev_generator:\n",
    "        dev_loss = criterion(model3(ibatch), ilabel)\n",
    "        total_loss += dev_loss\n",
    "    print(iepoch, total_loss)\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, sentence_len=91):\n",
    "    if x.size(1) > sentence_len:\n",
    "        return [len(ix) for ix in x], x[:,:sentence_len]\n",
    "    elif x.size(1) < sentence_len:\n",
    "        x_lengths = [len(ix) for ix in x]\n",
    "        padded_x = torch.zeros(x.size(0), sentence_len, dtype=torch.long)\n",
    "        # copy over the actual sequences\n",
    "        for i, x_len in enumerate(x_lengths):\n",
    "            sequence = x[i]\n",
    "            padded_x[i, 0:x_len] = sequence[:x_len]\n",
    "        return x_lengths, padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 82])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibatch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 91])\n",
      "torch.Size([128, 64])\n",
      "torch.Size([128, 4])\n"
     ]
    }
   ],
   "source": [
    "l,ie = pad(ibatch)\n",
    "print(ie.size())\n",
    "ie = embedding(ie).float()\n",
    "x = nn.utils.rnn.pack_padded_sequence(ie, l, batch_first=True)\n",
    "# Initialize hidden state with zeros\n",
    "#h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "\n",
    "# One time step\n",
    "out, _ = rnn(x)\n",
    "#out = self.drop_layer(out)\n",
    "out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "out = out.contiguous()[:,-1,:]\n",
    "print(np.shape(out))\n",
    "fc = nn.Linear(64,4)\n",
    "out = fc(out)\n",
    "print(np.shape(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
    "        super(EmoGRU, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.hidden_units = hidden_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # layers\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
    "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
    "    \n",
    "    def initialize_hidden_state(self, device):\n",
    "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
    "    \n",
    "    def forward(self, x, lens, device):\n",
    "        x = self.embedding(x)\n",
    "        self.hidden = self.initialize_hidden_state(device)\n",
    "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
    "        out = output[-1, :, :] \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out, self.hidden  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: \n",
      "tensor([25.9427])\n",
      "F-score: \n",
      "0.45296065571667343\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, loss_fn, test_generator):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on the development set, providing the loss and macro F1 score.\n",
    "    :param model: a model that performs 4-way emotion classification\n",
    "    :param loss_fn: a function that can calculate loss between the predicted and gold labels\n",
    "    :param test_generator: a DataLoader that provides batches of the testing set\n",
    "    \"\"\"\n",
    "    gold = []\n",
    "    predicted = []\n",
    "\n",
    "    # Keep track of the loss\n",
    "    loss = torch.zeros(1)  # requires_grad = False by default; float32 by default\n",
    "    if USE_CUDA:\n",
    "        loss = loss.cuda()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate over batches in the test dataset\n",
    "    with torch.no_grad():\n",
    "        for X_b, y_b in test_generator:\n",
    "            # Predict\n",
    "            y_pred = model(X_b)\n",
    "\n",
    "            # Save gold and predicted labels for F1 score - take the argmax to convert to class labels\n",
    "            gold.extend(y_b.cpu().detach().numpy())\n",
    "            predicted.extend(y_pred.argmax(1).cpu().detach().numpy())\n",
    "\n",
    "            loss += loss_fn(y_pred.double(), y_b.long()).data\n",
    "\n",
    "    # Print total loss and macro F1 score\n",
    "    print(\"Test loss: \")\n",
    "    print(loss)\n",
    "    print(\"F-score: \")\n",
    "    print(f1_score(gold, predicted, average='macro'))\n",
    "\n",
    "test_model(model, criterion, test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
