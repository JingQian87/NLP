{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Imports - our files\n",
    "import utils\n",
    "import models\n",
    "\n",
    "# Global definitions - data\n",
    "DATA_FN = 'data/crowdflower_data.csv'\n",
    "LABEL_NAMES = [\"happiness\", \"worry\", \"neutral\", \"sadness\"]\n",
    "\n",
    "# Global definitions - architecture\n",
    "EMBEDDING_DIM = 100  # We will use pretrained 100-dimensional GloVe\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "USE_CUDA = torch.cuda.is_available()  # CUDA will be available if you are using the GPU image for this homework\n",
    "\n",
    "# Global definitions - saving and loading data\n",
    "FRESH_START = False  # set this to false after running once with True to just load your preprocessed data from file\n",
    "#                     (good for debugging)\n",
    "TEMP_FILE = \"temporary_data.pkl\"  # if you set FRESH_START to false, the program will look here for your data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DataLoaders and embeddings from file....\n"
     ]
    }
   ],
   "source": [
    "# load the data and embeddings from file\n",
    "try:\n",
    "    with open(TEMP_FILE, \"rb\") as f:\n",
    "        print(\"Loading DataLoaders and embeddings from file....\")\n",
    "        train_generator, dev_generator, test_generator, embeddings, train_data = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"You need to have saved your data with FRESH_START=True once in order to load it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one works for just training\n",
    "class RNNModel_training(nn.Module):\n",
    "    def __init__(self, sentence_len, output_dim,hidden_dim, weight):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_dim = weight.size(1)       \n",
    "        # Define embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(self.embed_dim,hidden_dim,num_layers=2,batch_first=True)     \n",
    "        #self.drop_layer = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def get_len(self, x):\n",
    "        x_len = []\n",
    "        for ix in x:\n",
    "            if ix[-1] != 0:\n",
    "                x_len.append(len(ix))\n",
    "            else:\n",
    "                x_len.append((ix==0).nonzero()[0])           \n",
    "        return x_len\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x_lengths = self.get_len(x)\n",
    "        x = self.embedding(x).float()\n",
    "        out, _ = self.rnn(x)\n",
    "        #print(np.shape(out))\n",
    "        selected = torch.zeros(batch_size, self.hidden_dim, dtype=torch.float)\n",
    "        for i, l in enumerate(x_lengths):\n",
    "            selected[i,:] = out[i,l-1,:]\n",
    "        #print(np.shape(selected))\n",
    "        return self.fc(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, sentence_len, output_dim,hidden_dim, weight):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sentence_len = sentence_len\n",
    "        self.embed_dim = weight.size(1)       \n",
    "        # Define embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(self.embed_dim,hidden_dim,num_layers=2,batch_first=True)     \n",
    "        #self.drop_layer = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def get_len(self, x):\n",
    "        x_len = []\n",
    "        for ix in x:\n",
    "            if ix[-1] != 0:\n",
    "                x_len.append(len(ix))\n",
    "            else:\n",
    "                x_len.append((ix==0).nonzero()[0])           \n",
    "        return x_len\n",
    "    \n",
    "    def pad(self, x):\n",
    "        if x.size(1) > self.sentence_len:\n",
    "            return x[:,:self.sentence_len]\n",
    "        elif x.size(1) < self.sentence_len:\n",
    "            tmp = torch.zeros(x.size(0), self.sentence_len-x.size(1), dtype=torch.long)\n",
    "            return torch.cat((x,tmp), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x_lengths = self.get_len(x)\n",
    "        if x.size(1) != self.sentence_len:\n",
    "            x = self.pad(x)\n",
    "        x = self.embedding(x).float()\n",
    "        out, _ = self.rnn(x)\n",
    "        #print(np.shape(out))\n",
    "        selected = torch.zeros(batch_size, self.hidden_dim, dtype=torch.float)\n",
    "        for i, l in enumerate(x_lengths):\n",
    "            selected[i,:] = out[i,l-1,:]\n",
    "        #print(np.shape(selected))\n",
    "        return self.fc(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(26.5086, grad_fn=<AddBackward0>)\n",
      "1 tensor(25.7874, grad_fn=<AddBackward0>)\n",
      "2 tensor(25.3442, grad_fn=<AddBackward0>)\n",
      "3 tensor(25.5543, grad_fn=<AddBackward0>)\n",
      "4 tensor(25.3593, grad_fn=<AddBackward0>)\n",
      "5 tensor(25.3282, grad_fn=<AddBackward0>)\n",
      "6 tensor(25.3982, grad_fn=<AddBackward0>)\n",
      "7 tensor(25.3486, grad_fn=<AddBackward0>)\n",
      "8 tensor(25.4165, grad_fn=<AddBackward0>)\n",
      "9 tensor(25.4576, grad_fn=<AddBackward0>)\n",
      "10 tensor(25.7182, grad_fn=<AddBackward0>)\n",
      "11 tensor(25.5914, grad_fn=<AddBackward0>)\n",
      "12 tensor(26.5881, grad_fn=<AddBackward0>)\n",
      "13 tensor(25.7568, grad_fn=<AddBackward0>)\n",
      "14 tensor(25.7759, grad_fn=<AddBackward0>)\n",
      "15 tensor(25.7505, grad_fn=<AddBackward0>)\n",
      "16 tensor(25.6915, grad_fn=<AddBackward0>)\n",
      "17 tensor(26.0194, grad_fn=<AddBackward0>)\n",
      "18 tensor(25.7799, grad_fn=<AddBackward0>)\n",
      "19 tensor(25.9161, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "SENTENCE_LEN = 91\n",
    "model3 = RNNModel(SENTENCE_LEN, NUM_CLASSES, HIDDEN_DIM, embeddings)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters())\n",
    "  \n",
    "EPOCHS = 20\n",
    "losses = []\n",
    "for iepoch in range(EPOCHS): \n",
    "    i = 0\n",
    "    for train_batch, train_label in train_generator:\n",
    "#         if i>10:\n",
    "#             break\n",
    "#         i += 1\n",
    "        # Compute and print loss\n",
    "        loss = criterion(model3(train_batch),train_label)\n",
    "        #print(loss.item()) \n",
    "\n",
    "        # Zero the gradients\n",
    "        model3.zero_grad()\n",
    "\n",
    "        # perform a backward pass (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "    #print(loss.item()) \n",
    "    total_loss = 0\n",
    "    for ibatch, ilabel in dev_generator:\n",
    "        dev_loss = criterion(model3(ibatch), ilabel)\n",
    "        total_loss += dev_loss\n",
    "    print(iepoch, total_loss)\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17635, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, loss_fn, test_generator):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on the development set, providing the loss and macro F1 score.\n",
    "    :param model: a model that performs 4-way emotion classification\n",
    "    :param loss_fn: a function that can calculate loss between the predicted and gold labels\n",
    "    :param test_generator: a DataLoader that provides batches of the testing set\n",
    "    \"\"\"\n",
    "    gold = []\n",
    "    predicted = []\n",
    "\n",
    "    # Keep track of the loss\n",
    "    loss = torch.zeros(1)  # requires_grad = False by default; float32 by default\n",
    "    if USE_CUDA:\n",
    "        loss = loss.cuda()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate over batches in the test dataset\n",
    "    with torch.no_grad():\n",
    "        for X_b, y_b in test_generator:\n",
    "            # Predict\n",
    "            y_pred = model(X_b)\n",
    "\n",
    "            # Save gold and predicted labels for F1 score - take the argmax to convert to class labels\n",
    "            gold.extend(y_b.cpu().detach().numpy())\n",
    "            predicted.extend(y_pred.argmax(1).cpu().detach().numpy())\n",
    "\n",
    "            loss += loss_fn(y_pred.double(), y_b.long()).data\n",
    "\n",
    "    # Print total loss and macro F1 score\n",
    "    print(\"Test loss: \")\n",
    "    print(loss)\n",
    "    print(\"F-score: \")\n",
    "    print(f1_score(gold, predicted, average='macro'))\n",
    "\n",
    "test_model(model3, criterion, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
