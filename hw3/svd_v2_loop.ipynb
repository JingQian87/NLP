{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import process\n",
    "import numpy as np\n",
    "text = 'data/brown.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename, 'r'):\n",
    "            yield [word.lower() for word in tokenizer.tokenize(line)]\n",
    "#sentence = MySentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# count unigrams\n",
    "def vocab_index(sentences):\n",
    "    word_counts = Counter()\n",
    "    for x in sentences:\n",
    "        word_counts.update(x)\n",
    "    print(len(word_counts))\n",
    "    print(word_counts.most_common(5))\n",
    "    print(word_counts.most_common()[-5:])\n",
    "    \n",
    "    # generate index for words in vocabulary\n",
    "    index_dict = dict()\n",
    "    ii = 0\n",
    "    for i in word_counts:\n",
    "        index_dict[i] = ii\n",
    "        ii += 1\n",
    "    \n",
    "    return index_dict\n",
    "\n",
    "#index_dict = vocab_index(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count co-occurance as a dictionary \"joint\"\n",
    "def cooc_dict(sentences, iwin):\n",
    "    joint = Counter()\n",
    "    for isen in sentences:\n",
    "        for j, word in enumerate(isen):\n",
    "            index_min = max(0, j-iwin)\n",
    "            index_max = min(len(isen), j+iwin+1)\n",
    "            index = [ii for ii in range(index_min, index_max) if ii!=j]\n",
    "            for iin in index:\n",
    "                joint[(word, isen[iin])] += 1\n",
    "    return joint\n",
    "\n",
    "# joint = cooc_dict(sentence, 2)\n",
    "# print(len(joint))\n",
    "# print(joint.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform count joint to sparse matrix\n",
    "from scipy import sparse\n",
    "def cooc_matrix(joint_dict, index_dict):\n",
    "    row_index = []\n",
    "    col_index = []\n",
    "    values = []\n",
    "    for (wi,wj), count in joint.items():\n",
    "        row = index_dict[wi]\n",
    "        col = index_dict[wj]\n",
    "        value = count\n",
    "        row_index.append(row)\n",
    "        col_index.append(col)\n",
    "        values.append(value)\n",
    "    return sparse.csr_matrix((values, (row_index, col_index)))\n",
    "#joint_matrix = cooc_matrix(joint, index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ppmi_matrix(joint_matrix):\n",
    "   # calculate the column sum, row sum and total sum of the co-occur matrix.\n",
    "    sum_a0 = joint_matrix.sum(axis=0)\n",
    "    print(np.shape(sum_a0))\n",
    "    sum_a1 = joint_matrix.sum(axis=1)\n",
    "    print(np.shape(sum_a1))\n",
    "    sum_total = joint_matrix.sum()\n",
    "    print(sum_total) \n",
    "   \n",
    "    # find the non-zero elements in the sparse matrix\n",
    "    nonzero_index = joint_matrix.nonzero()\n",
    "    num_nonzero = np.shape(nonzero_index)[1]\n",
    "    print(num_nonzero)\n",
    "    \n",
    "    # calculate values for non-zero ppmi\n",
    "    ppmi_values = []\n",
    "    for i in range(num_nonzero):\n",
    "        row = nonzero_index[0][i]\n",
    "        col = nonzero_index[1][i]\n",
    "        pwc_scaled = joint_matrix[row, col]\n",
    "        pwpc_scaled = sum_a1[row,0]*sum_a0[0,col]/sum_total\n",
    "        if pwc_scaled > pwpc_scaled:\n",
    "            value = math.log(pwc_scaled/pwpc_scaled)\n",
    "        else:\n",
    "            value = 0\n",
    "        ppmi_values.append(value)\n",
    "    \n",
    "    return sparse.csr_matrix((ppmi_values, nonzero_index)) \n",
    "\n",
    "#ppmi = ppmi_matrix(joint_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import linalg\n",
    "# truncate with svd\n",
    "def ppmi_svd(ppmi, idim):\n",
    "    uu,ss,vv = linalg.svds(ppmi, idim)\n",
    "    print(np.shape(uu),np.shape(ss),np.shape(vv)) \n",
    "  \n",
    "    sigma_sr = np.diag([x**0.5 for x in ss])\n",
    "    return np.matmul(uu,sigma_sr)\n",
    "\n",
    "#word_vecs = ppmi_svd(ppmi, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_wv(word_vecs, index_dict, iwin, idim):\n",
    "    keys = list(index_dict.keys())\n",
    "    print(np.shape(keys))\n",
    "    \n",
    "    f1 = open('../../NLPdata/hw3/savedModel/wv_svd_win%d_dim%d.txt' %(iwin, idim),'w')\n",
    "    for i in range(len(keys)):\n",
    "        f1.write(keys[i]+' '+' '.join(str(x) for x in word_vecs[i,:]))\n",
    "        f1.write('\\r\\n')\n",
    "    f1.close()    \n",
    "    \n",
    "#save_wv(word_vecs, index_dict, 2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_paras(corpus, iwin, idim):\n",
    "    index_dict = vocab_index(corpus)\n",
    "    joint = cooc_dict(corpus, iwin)\n",
    "    joint_matrix = cooc_matrix(joint, index_dict)\n",
    "    ppmi = ppmi_matrix(joint_matrix)\n",
    "    word_vecs = ppmi_svd(ppmi, idim)\n",
    "    save_wv(word_vecs, index_dict, iwin, idim)\n",
    "    \n",
    "#svd_paras(sentence,3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test final win10, dim1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "14851962\n",
      "4815005\n"
     ]
    }
   ],
   "source": [
    "iwin = 10\n",
    "idim = 1000\n",
    "index_dict = vocab_index(sentence)\n",
    "joint = cooc_dict(sentence, iwin)\n",
    "joint_matrix = cooc_matrix(joint, index_dict)\n",
    "ppmi = ppmi_matrix(joint_matrix)\n",
    "nonzero_index = joint_matrix.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4815005)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(nonzero_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 100) (100,) (100, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 300) (300,) (300, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 1000) (1000,) (1000, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 100) (100,) (100, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 300) (300,) (300, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 1000) (1000,) (1000, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 100) (100,) (100, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 300) (300,) (300, 42432)\n",
      "(42432,)\n",
      "42432\n",
      "[('the', 70003), ('of', 36473), ('and', 28935), ('to', 26247), ('a', 23502)]\n",
      "[('perelman', 1), ('exhaling', 1), ('aviary', 1), ('boucle', 1), ('stupefying', 1)]\n",
      "(1, 42432)\n",
      "(42432, 1)\n",
      "3794604\n",
      "1468689\n",
      "(42432, 1000) (1000,) (1000, 42432)\n",
      "(42432,)\n"
     ]
    }
   ],
   "source": [
    "windowList = [2,5,10]\n",
    "dimList = [100,300,1000]\n",
    "\n",
    "sentence = MySentences(text)\n",
    "for iwin in windowList:\n",
    "    for idim in dimList:\n",
    "        svd_paras(sentence, iwin, idim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# following are test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uncle', 0.9999999999999993),\n",
       " ('randolph', 0.21424651831115082),\n",
       " ('ffortescue', 0.15364112842611377),\n",
       " ('conspires', 0.14258384785514255),\n",
       " ('dragooned', 0.14046243950105333),\n",
       " ('countrey', 0.1396034035433304),\n",
       " ('stowe', 0.1294718674981437),\n",
       " ('replanted', 0.12937519810706688),\n",
       " ('grandparents', 0.11413975147356778),\n",
       " ('lorde', 0.11341216492243941)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cos similarity with ppmi\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def ww_sim(word, mat, topn=10):\n",
    "    indx = index_dict[word]\n",
    "    if isinstance(mat, sparse.csr_matrix):\n",
    "        v1 = mat.getrow(indx)\n",
    "    else:\n",
    "        v1 = mat[indx:indx+1, :]\n",
    "    sims = cosine_similarity(mat, v1).flatten()\n",
    "    sindxs = np.argsort(-sims)\n",
    "    sim_word_scores = [(word_dict[sindx], sims[sindx]) for sindx in sindxs[0:topn]]\n",
    "    return sim_word_scores\n",
    "\n",
    "ww_sim('uncle', ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 1.0),\n",
       " ('idal', 0.7426855705101922),\n",
       " ('dissenters', 0.6487736746520316),\n",
       " ('matriarchal', 0.5460884319403518),\n",
       " ('amazons', 0.5286572527913542),\n",
       " ('significantly', 0.5125824483005444),\n",
       " ('psithyrus', 0.5083448354841025),\n",
       " ('colombian', 0.5068891562074264),\n",
       " ('predictable', 0.5040026593735853),\n",
       " ('male', 0.4945138048954064)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim(\"female\",word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uncle', 0.9999999999999997),\n",
       " ('countrey', 0.8359475206229168),\n",
       " ('ffortescue', 0.8255886328699187),\n",
       " ('dragooned', 0.7734844249562545),\n",
       " ('remus', 0.7041995914120744),\n",
       " ('morse', 0.6642162573971708),\n",
       " ('indisposition', 0.6404643774887171),\n",
       " ('farnworth', 0.6180976883988671),\n",
       " ('beecher', 0.5971136029647994),\n",
       " ('linda', 0.5843139670256834)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim(\"uncle\",word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('first', 1.0),\n",
       " ('mubarak', 0.8043438743016806),\n",
       " ('tuxedoed', 0.8033108086162087),\n",
       " ('nighters', 0.7977749772268158),\n",
       " ('platitudinous', 0.7950816094711803),\n",
       " ('gracias', 0.7943228326127885),\n",
       " ('angered', 0.7770089916923083),\n",
       " ('tullio', 0.7756776667479051),\n",
       " ('prettiness', 0.7750187800324218),\n",
       " ('foote', 0.7739161161800336)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim(\"first\",word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uncle', 1.0),\n",
       " ('countrey', 0.8951414851006021),\n",
       " ('ffortescue', 0.8706983548734593),\n",
       " ('dragooned', 0.8555405718071133),\n",
       " ('remus', 0.7458469743586553),\n",
       " ('beecher', 0.7003451258521559),\n",
       " ('indisposition', 0.6668285423281214),\n",
       " ('morse', 0.6442708218591424),\n",
       " ('farnworth', 0.6238947231908696),\n",
       " ('manly', 0.5652279520513261)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim(\"uncle\",word_vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 0.9999999999999997),\n",
       " ('idal', 0.7472648119196135),\n",
       " ('dissenters', 0.6602121619841566),\n",
       " ('matriarchal', 0.5355959892322617),\n",
       " ('amazons', 0.5137198417249681),\n",
       " ('colombian', 0.5111274085873134),\n",
       " ('psithyrus', 0.506383123747987),\n",
       " ('digs', 0.49014346941055265),\n",
       " ('significantly', 0.4886866635444046),\n",
       " ('andrenas', 0.4753720225751541)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_sim(\"female\",uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/Users/mac/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "unorm = uu / np.sqrt(np.sum(uu*uu, axis=1, keepdims=True))\n",
    "vnorm = vv / np.sqrt(np.sum(vv*vv, axis=0, keepdims=True))\n",
    "#word_vecs = unorm\n",
    "#word_vecs = vnorm.T\n",
    "word_vecs2 = uu + vv.T\n",
    "word_vecs_norm = word_vecs / np.sqrt(np.sum(word_vecs*word_vecs, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.3880257 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , 10.39186573,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , 10.39906501, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., 14.7839714 ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        16.21563346,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , 24.37001025]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag([x**0.5 for x in ss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (42281,100) (100,100) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-4633ba545606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mppmi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (42281,100) (100,100) "
     ]
    }
   ],
   "source": [
    "t = np.diag(ss)\n",
    "uu*t*vv == ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 178)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_a0[0,2],sum_a1[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-f09a8245275d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.shape(np.matmul(np.matmul(uu,t),vv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0, ..., 42279, 42280, 42280], dtype=int32),\n",
       " array([    1,     2,     3, ..., 42280,  6523, 42279], dtype=int32))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_matrix[nonzero_index[0][0],nonzero_index[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Sentences iterable can be simply a list, but for larger corpora, consider a generator that streams the sentences directly from disk/network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.0\n",
      "  (0, 2)\t0.0\n",
      "  (0, 3)\t0.0\n",
      "  (0, 7)\t0.0\n",
      "  (0, 29)\t0.0\n",
      "  (0, 30)\t0.0\n",
      "  (0, 31)\t0.0\n",
      "  (0, 58)\t0.0\n",
      "  (0, 59)\t0.0\n",
      "  (0, 60)\t0.0\n",
      "  (0, 64)\t0.0\n",
      "  (0, 66)\t0.0\n",
      "  (0, 67)\t0.0\n",
      "  (0, 90)\t0.0\n",
      "  (0, 106)\t0.0\n",
      "  (0, 119)\t0.0\n",
      "  (0, 129)\t0.0\n",
      "  (0, 130)\t0.0\n",
      "  (0, 131)\t0.0\n",
      "  (0, 138)\t0.0\n",
      "  (0, 139)\t0.0\n",
      "  (0, 149)\t0.0\n",
      "  (0, 150)\t0.0\n",
      "  (0, 151)\t0.0\n",
      "  (0, 156)\t0.0\n",
      "  (0, 157)\t0.0\n",
      "  (0, 158)\t0.0\n",
      "  (0, 210)\t0.0\n",
      "  (0, 211)\t0.0\n",
      "  (0, 215)\t0.0\n",
      "  (0, 222)\t0.0\n",
      "  (0, 235)\t0.0\n",
      "  (0, 236)\t0.0\n",
      "  (0, 237)\t0.0\n",
      "  (0, 241)\t0.6394438532335271\n",
      "  (0, 242)\t0.0\n",
      "  (0, 243)\t0.0\n",
      "  (0, 244)\t0.0\n",
      "  (0, 246)\t0.6394438532335271\n",
      "  (0, 252)\t0.0\n",
      "  (0, 304)\t0.0\n",
      "  (0, 1051)\t0.0\n",
      "  (0, 1212)\t0.0\n",
      "  (0, 2258)\t0.0\n",
      "  (0, 4037)\t0.0\n",
      "  (0, 4165)\t0.0\n",
      "  (0, 6212)\t0.0\n",
      "  (0, 6789)\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(ppmi[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-d30a2fe9d97f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../NLPdata/hw3/savedModel/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "word_vecs.save(\"../../NLPdata/hw3/savedModel/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13891, 100)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.63849412e-04, -9.70924308e-06, -3.89196601e-04, -1.99606045e-04,\n",
       "       -1.52572737e-04,  3.92952168e-04,  4.11227720e-16,  6.34080014e-04,\n",
       "       -8.64653808e-05, -1.56360244e-03, -5.49293412e-15, -2.56142763e-17,\n",
       "        1.16559588e-04, -4.07202049e-05,  4.32493179e-05,  2.21068619e-04,\n",
       "        3.71345924e-04,  4.73482216e-04,  8.14642407e-17, -4.92336396e-04,\n",
       "       -1.26622883e-04,  1.42008801e-15,  6.22602646e-04,  9.23833035e-05,\n",
       "       -1.18927200e-04,  9.85675300e-17,  2.16759825e-05, -4.91414635e-16,\n",
       "       -3.35825277e-04, -3.18863859e-16, -1.83852395e-04, -8.15787470e-05,\n",
       "        2.11504127e-17, -8.56977114e-17, -6.59427894e-05,  2.85409917e-04,\n",
       "       -1.09294355e-16,  6.32557204e-05,  5.77771367e-05,  8.97643609e-05,\n",
       "       -4.61098228e-05,  2.48408268e-05, -3.19926818e-04, -9.76574519e-05,\n",
       "       -5.61873316e-05,  6.93308960e-04,  3.10089953e-15, -1.51924772e-04,\n",
       "       -2.84483907e-05,  1.10950504e-04, -5.57999895e-17,  1.62489884e-05,\n",
       "       -1.04200530e-04, -5.91413011e-05,  3.16817047e-04,  5.76590544e-05,\n",
       "        1.64330426e-06, -5.69516610e-04,  9.03169577e-06, -1.88214933e-05,\n",
       "       -1.12542091e-04, -1.75870998e-04, -9.78829467e-05,  7.43822831e-05,\n",
       "        2.59406076e-04, -3.80664763e-04,  1.97051600e-04, -3.02960186e-05,\n",
       "        2.94307443e-05, -1.90648587e-04, -5.88568542e-05, -1.07930207e-04,\n",
       "       -4.16241997e-04,  4.30507776e-05,  1.45312311e-04,  1.95227415e-04,\n",
       "        4.36293493e-03, -4.09497445e-05, -1.27053849e-05, -1.73563958e-04,\n",
       "       -2.35633146e-04, -8.45838896e-05,  3.96022024e-05,  4.14037738e-05,\n",
       "        1.62074476e-05, -7.53819548e-06,  6.75414849e-05,  1.29570872e-06,\n",
       "       -3.44006714e-05,  5.28233248e-05, -2.69400607e-05,  2.61495000e-04,\n",
       "        8.93578253e-06,  6.34366818e-06, -6.09949907e-06,  7.08059894e-05,\n",
       "        3.08302097e-05, -9.56924279e-07,  3.64591979e-07,  2.60713917e-06])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
