{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import lemmatize\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec-SkipGram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corpus And Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(row):\n",
    "    \"\"\"\n",
    "    Remove common punctuations from the row\n",
    "    \n",
    "    :param row: a string without '\\n'\n",
    "    :return: original input with common punctuations removed\n",
    "    \"\"\"\n",
    "    return re.sub(\"\"\"[,.!'\":;`^~\\-<>]\"\"\", '', row)\n",
    "\n",
    "def load_data_tolist(lemma = False):\n",
    "    \"\"\"\n",
    "    A generator return a preprocessed line of sentence\n",
    "    the yielded result is a list contains the tokens in each sentence\n",
    "    \"\"\"\n",
    "    with open(\"./data/brown.txt\") as corpus:\n",
    "        while corpus:\n",
    "            line = corpus.readline()\n",
    "            # end of file\n",
    "            if not line:\n",
    "                break\n",
    "            # 1. get rid of punctuations\n",
    "            line = remove_punctuations(line)\n",
    "            # 2. lower\n",
    "            line = line.lower()\n",
    "            # 3. if lemmatize\n",
    "            if lemma:\n",
    "                line = [lem.decode('utf-8').split('/')[0] for lem in lemmatize(line, min_length=1)]\n",
    "            else:\n",
    "                line = line.split()\n",
    "            yield line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lemmatized corpus....\n",
      "Writing unlemmatized corpus....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write lines to local disk to boost performance\n",
    "\"\"\"\n",
    "def write_to_file(output_fname, row_iterator):\n",
    "    with open(output_fname, \"w\", encoding =\"utf-8\") as output_file:\n",
    "        for row_list in row_iterator:\n",
    "            row = \" \".join(row_list)\n",
    "            output_file.write(f\"\"\"{row}\\n\"\"\")\n",
    "\n",
    "def write_preprocessed_corpus():\n",
    "#     print(\"Writing lemmatized corpus....\")\n",
    "#     lemmatized_corpus = load_data_tolist(True)\n",
    "#     write_to_file(\"./data/lemmatized_brown.txt\", lemmatized_corpus)\n",
    "    \n",
    "    print(\"Writing unlemmatized corpus....\")\n",
    "    unlemmatized_corpus = load_data_tolist(False)\n",
    "    write_to_file(\"./data/unlemmatized_brown.txt\", unlemmatized_corpus)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "# write_preprocessed_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2Vec Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_word2vec_model_tofile(model_input_file, verbose = True):\n",
    "    \"\"\"\n",
    "    Training word2vec models with all parameter combinations\n",
    "    and write these result to files in 'model' folder\n",
    "    \n",
    "    \"\"\"\n",
    "    # use un lemmatized corpus to train the model\n",
    "    \n",
    "\n",
    "    windows = (2,5,10)\n",
    "    dimensions = (100,300,1000)\n",
    "    negatives = (1,5,15)\n",
    "    for w in windows:\n",
    "        for dim in dimensions:\n",
    "            for n in negatives:\n",
    "                model = Word2Vec(corpus_file = model_input_file, workers=6, sg = 1, min_count= 5,\n",
    "                     window= w, size = dim, negative = n)\n",
    "                model_output_filename = f\"model/w{w}s{dim}n{n}-word2vec.bin\"\n",
    "                if verbose:\n",
    "                    print(f\"Writing {model_output_filename}...\")\n",
    "                model.wv.save_word2vec_format(model_output_filename, binary= True)\n",
    "    if verbose:\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/w2s100n1-word2vec.bin...\n",
      "Writing model/w2s100n5-word2vec.bin...\n",
      "Writing model/w2s100n15-word2vec.bin...\n",
      "Writing model/w2s300n1-word2vec.bin...\n",
      "Writing model/w2s300n5-word2vec.bin...\n",
      "Writing model/w2s300n15-word2vec.bin...\n",
      "Writing model/w2s1000n1-word2vec.bin...\n",
      "Writing model/w2s1000n5-word2vec.bin...\n",
      "Writing model/w2s1000n15-word2vec.bin...\n",
      "Writing model/w5s100n1-word2vec.bin...\n",
      "Writing model/w5s100n5-word2vec.bin...\n",
      "Writing model/w5s100n15-word2vec.bin...\n",
      "Writing model/w5s300n1-word2vec.bin...\n",
      "Writing model/w5s300n5-word2vec.bin...\n",
      "Writing model/w5s300n15-word2vec.bin...\n",
      "Writing model/w5s1000n1-word2vec.bin...\n",
      "Writing model/w5s1000n5-word2vec.bin...\n",
      "Writing model/w5s1000n15-word2vec.bin...\n",
      "Writing model/w10s100n1-word2vec.bin...\n",
      "Writing model/w10s100n5-word2vec.bin...\n",
      "Writing model/w10s100n15-word2vec.bin...\n",
      "Writing model/w10s300n1-word2vec.bin...\n",
      "Writing model/w10s300n5-word2vec.bin...\n",
      "Writing model/w10s300n15-word2vec.bin...\n",
      "Writing model/w10s1000n1-word2vec.bin...\n",
      "Writing model/w10s1000n5-word2vec.bin...\n",
      "Writing model/w10s1000n15-word2vec.bin...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model_input_file = \"./data/unlemmatized_brown.txt\"\n",
    "write_word2vec_model_tofile(model_input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_word2vec_models(verbose = True):\n",
    "    \"\"\"\n",
    "    Evaluating word2vec models and return all results in a dict\n",
    "    \"\"\"\n",
    "    windows = (2,5,10)\n",
    "    dimensions = (100,300,1000)\n",
    "    negatives = (1,5,15)\n",
    "    evaluation_results = {}\n",
    "    for w in windows:\n",
    "        for d in dimensions:\n",
    "            for n in negatives:\n",
    "                key = f\"w{w}d{d}n{n}\"\n",
    "                model_output_filename = f\"model/w{w}s{d}n{n}-word2vec.bin\"\n",
    "                if verbose:\n",
    "                    print(f\"Evaluating model {key}\")\n",
    "                evaluation_results[key] = evaluate.evaluate_models([model_output_filename], verbose=False)\n",
    "    if verbose:\n",
    "        print(\"Done!\")\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model w2d100n1\n",
      "Evaluating model w2d100n5\n",
      "Evaluating model w2d100n15\n",
      "Evaluating model w2d300n1\n",
      "Evaluating model w2d300n5\n",
      "Evaluating model w2d300n15\n",
      "Evaluating model w2d1000n1\n",
      "Evaluating model w2d1000n5\n",
      "Evaluating model w2d1000n15\n",
      "Evaluating model w5d100n1\n",
      "Evaluating model w5d100n5\n",
      "Evaluating model w5d100n15\n",
      "Evaluating model w5d300n1\n",
      "Evaluating model w5d300n5\n",
      "Evaluating model w5d300n15\n",
      "Evaluating model w5d1000n1\n",
      "Evaluating model w5d1000n5\n",
      "Evaluating model w5d1000n15\n",
      "Evaluating model w10d100n1\n",
      "Evaluating model w10d100n5\n",
      "Evaluating model w10d100n15\n",
      "Evaluating model w10d300n1\n",
      "Evaluating model w10d300n5\n",
      "Evaluating model w10d300n15\n",
      "Evaluating model w10d1000n1\n",
      "Evaluating model w10d1000n5\n",
      "Evaluating model w10d1000n15\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate\n",
    "\"\"\"\n",
    "w2v_eval_results = eval_word2vec_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_results(eval_results):\n",
    "    \"\"\"\n",
    "    Print the evaluation result for each model.\n",
    "    The metrics include\n",
    "    1. correlation on WordSim\n",
    "    2. BATS: male-female\n",
    "    3. BATS: name-nationality\n",
    "    4. BATS: things-color\n",
    "    5. accuracy on MSR\n",
    "    \"\"\"\n",
    "    for model in eval_results:\n",
    "        result = eval_results[model][0]\n",
    "        print(f\"\"\"\n",
    "        Model:{model}\n",
    "        WordSIM: {result['wordsim'].correlation}\\t MSR: {result['msr']}\n",
    "        BAT1: {result['bats']['E10 [male - female]']}\\t BAT2: {result['bats']['E04 [name - nationality]']}\\t, BAT3: {result['bats']['E09 [things - color]']}\n",
    "        ==============================================\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Model:w2d100n1\n",
      "        WordSIM: 0.028208350592355845\t MSR: 0.672463768115942\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.0\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d100n5\n",
      "        WordSIM: 0.2121214994403418\t MSR: 0.672463768115942\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.0\t, BAT3: 0.38461538461538464\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d100n15\n",
      "        WordSIM: 0.2380593677457007\t MSR: 0.6718840579710145\n",
      "        BAT1: 0.2631578947368421\t BAT2: 0.05263157894736842\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d300n1\n",
      "        WordSIM: 0.023532043805981926\t MSR: 0.6666666666666666\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.0\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d300n5\n",
      "        WordSIM: 0.21096234006103473\t MSR: 0.6718840579710145\n",
      "        BAT1: 0.15789473684210525\t BAT2: 0.0\t, BAT3: 0.19230769230769232\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d300n15\n",
      "        WordSIM: 0.23182137517251003\t MSR: 0.6759420289855073\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.0\t, BAT3: 0.2692307692307692\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d1000n1\n",
      "        WordSIM: 0.011125479880605913\t MSR: 0.6684057971014493\n",
      "        BAT1: 0.05263157894736842\t BAT2: 0.0\t, BAT3: 0.07692307692307693\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d1000n5\n",
      "        WordSIM: 0.21621239282101135\t MSR: 0.6718840579710145\n",
      "        BAT1: 0.05263157894736842\t BAT2: 0.0\t, BAT3: 0.23076923076923078\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w2d1000n15\n",
      "        WordSIM: 0.22372301055069832\t MSR: 0.672463768115942\n",
      "        BAT1: 0.21052631578947367\t BAT2: 0.0\t, BAT3: 0.38461538461538464\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d100n1\n",
      "        WordSIM: 0.1356983607449888\t MSR: 0.6678260869565218\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.05263157894736842\t, BAT3: 0.2692307692307692\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d100n5\n",
      "        WordSIM: 0.25945481304805307\t MSR: 0.6776811594202898\n",
      "        BAT1: 0.21052631578947367\t BAT2: 0.0\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d100n15\n",
      "        WordSIM: 0.29746555672067854\t MSR: 0.6834782608695652\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d300n1\n",
      "        WordSIM: 0.11105470234551443\t MSR: 0.6660869565217391\n",
      "        BAT1: 0.3684210526315789\t BAT2: 0.0\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d300n5\n",
      "        WordSIM: 0.2626286462655265\t MSR: 0.6742028985507247\n",
      "        BAT1: 0.2631578947368421\t BAT2: 0.0\t, BAT3: 0.11538461538461539\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d300n15\n",
      "        WordSIM: 0.2885344291326057\t MSR: 0.6828985507246377\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.0\t, BAT3: 0.15384615384615385\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d1000n1\n",
      "        WordSIM: 0.13029575631028215\t MSR: 0.6695652173913044\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.05263157894736842\t, BAT3: 0.23076923076923078\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d1000n5\n",
      "        WordSIM: 0.24065070441549521\t MSR: 0.6747826086956522\n",
      "        BAT1: 0.05263157894736842\t BAT2: 0.0\t, BAT3: 0.11538461538461539\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w5d1000n15\n",
      "        WordSIM: 0.28561873785038305\t MSR: 0.6811594202898551\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.038461538461538464\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d100n1\n",
      "        WordSIM: 0.19096552818187743\t MSR: 0.6672463768115942\n",
      "        BAT1: 0.05263157894736842\t BAT2: 0.0\t, BAT3: 0.07692307692307693\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d100n5\n",
      "        WordSIM: 0.320135668980145\t MSR: 0.6742028985507247\n",
      "        BAT1: 0.21052631578947367\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d100n15\n",
      "        WordSIM: 0.3375332686728391\t MSR: 0.6765217391304348\n",
      "        BAT1: 0.2631578947368421\t BAT2: 0.0\t, BAT3: 0.038461538461538464\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d300n1\n",
      "        WordSIM: 0.18358033534728402\t MSR: 0.6655072463768116\n",
      "        BAT1: 0.15789473684210525\t BAT2: 0.0\t, BAT3: 0.07692307692307693\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d300n5\n",
      "        WordSIM: 0.3125652556609366\t MSR: 0.6695652173913044\n",
      "        BAT1: 0.15789473684210525\t BAT2: 0.05263157894736842\t, BAT3: 0.07692307692307693\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d300n15\n",
      "        WordSIM: 0.3454160774865714\t MSR: 0.6753623188405797\n",
      "        BAT1: 0.15789473684210525\t BAT2: 0.0\t, BAT3: 0.038461538461538464\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d1000n1\n",
      "        WordSIM: 0.18770418922364096\t MSR: 0.6695652173913044\n",
      "        BAT1: 0.21052631578947367\t BAT2: 0.05263157894736842\t, BAT3: 0.11538461538461539\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d1000n5\n",
      "        WordSIM: 0.3131217921721892\t MSR: 0.6666666666666666\n",
      "        BAT1: 0.10526315789473684\t BAT2: 0.0\t, BAT3: 0.038461538461538464\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:w10d1000n15\n",
      "        WordSIM: 0.3482848073545845\t MSR: 0.6742028985507247\n",
      "        BAT1: 0.05263157894736842\t BAT2: 0.05263157894736842\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print_eval_results(w2v_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Co-occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_occurence_matrix(corpus_filename, token_to_index, window):\n",
    "    \"\"\"\n",
    "    Create co-occurence matrix using corpus from 'corpus_filename'\n",
    "    \n",
    "    :param corpus_filename: corpus file\n",
    "    :param token_to_index: dict, mapping token to index, which is used to set the meaning of row/col\n",
    "    :param window: window size of the co-occurence matrix\n",
    "    \n",
    "    :return: the created co-occurence matrix\n",
    "    \"\"\"\n",
    "    word_len = len(token_to_index)\n",
    "    co_occurence_mat = scipy.sparse.lil_matrix((word_len,word_len))\n",
    "    \n",
    "    with open(corpus_filename) as f:\n",
    "        for line in f:\n",
    "            line = line.split()\n",
    "            for i, word in enumerate(line):\n",
    "                for j in range(max(i-window,0),min(i + window + 1,len(line))):\n",
    "                    # skip the word itself\n",
    "                    if j == i: continue\n",
    "\n",
    "                    co_occurence_mat[token_to_index[word],token_to_index[line[j]]]+=1\n",
    "\n",
    "    return co_occurence_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get all tokens and build the transform dict\n",
    "\"\"\"\n",
    "model_input_file = \"./data/unlemmatized_brown.txt\"\n",
    "\n",
    "\n",
    "with open(model_input_file) as f:\n",
    "    corpus = f.read()\n",
    "    tokens = set(corpus.split())\n",
    "\n",
    "token_to_index = {}\n",
    "for i, tok in enumerate(tokens):\n",
    "    token_to_index[tok] = i\n",
    "    \n",
    "# save to file\n",
    "token_to_index_file = \"data/word_to_index.pkl\"\n",
    "with open(token_to_index_file, \"wb\") as f:\n",
    "    pickle.dump(json.dumps(token_to_index), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the token-index mapping back from disk\n",
    "\"\"\"\n",
    "with open(token_to_index_file, \"rb\") as f:\n",
    "    token_to_index = json.loads(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate co-occurence matrix\n",
    "\"\"\"\n",
    "# w2coocurence_mat = create_co_occurence_matrix(model_input_file, token_to_index, 2)\n",
    "# w5coocurence_mat = create_co_occurence_matrix(model_input_file, token_to_index, 5)\n",
    "# w10coocurence_mat = create_co_occurence_matrix(model_input_file, token_to_index, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save co-occurence matrix\n",
    "\"\"\"\n",
    "# scipy.sparse.save_npz(\"data/w2coocurence_mat.npz\", scipy.sparse.coo_matrix(w2coocurence_mat) )\n",
    "# scipy.sparse.save_npz(\"data/w5coocurence_mat.npz\", scipy.sparse.coo_matrix(w5coocurence_mat) )\n",
    "# scipy.sparse.save_npz(\"data/w10coocurence_mat.npz\", scipy.sparse.coo_matrix(w10coocurence_mat) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load back the co-occurence matrix\n",
    "\"\"\"\n",
    "w2coocurence_mat = scipy.sparse.load_npz(\"data/w2coocurence_mat.npz\")\n",
    "w5coocurence_mat = scipy.sparse.load_npz(\"data/w5coocurence_mat.npz\")\n",
    "w10coocurence_mat = scipy.sparse.load_npz(\"data/w10coocurence_mat.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating PPMI Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ppmi_matrix(cooccurence_matrix, verbose = True):\n",
    "    \"\"\"\n",
    "    Calculate PPMI matrix based on the input co-occurence matrix\n",
    "    \n",
    "    :return: PPMI matrix\n",
    "    \"\"\"\n",
    "    ppmi_matrix = cooccurence_matrix.tolil()\n",
    "    ppmi_row_matrix = cooccurence_matrix.tocsr()\n",
    "    ppmi_col_matrix = cooccurence_matrix.tocsc()\n",
    "    total = np.sum(ppmi_matrix)\n",
    "    # memorizing col sum and row sum\n",
    "    rowsum = []\n",
    "    for i in range(ppmi_matrix.shape[0]):\n",
    "        if verbose:\n",
    "            print(f\"\\r Summing up row {i}  \", end = '')\n",
    "        rowsum.append(ppmi_row_matrix[i,:].sum())\n",
    "    colsum = []\n",
    "    for j in range(ppmi_matrix.shape[1]):\n",
    "        if verbose:\n",
    "            print(f\"\\r Summing up col {j}  \", end = '')\n",
    "        colsum.append(ppmi_col_matrix[:, j].sum())\n",
    "    \n",
    "    # update PPMI\n",
    "    for row in range(ppmi_matrix.shape[0]):\n",
    "        # print percentage\n",
    "        if verbose:\n",
    "            print(f\"\\rProcessing {row}/{ppmi_matrix.shape[0]} row\", end = '')\n",
    "\n",
    "        for col in range(ppmi_matrix.shape[1]):\n",
    "            # skip 0 prob\n",
    "            if ppmi_matrix[row,col] == 0: \n",
    "                continue\n",
    "            PMI = np.log(ppmi_matrix[row, col] * total / rowsum[row] / colsum[col])\n",
    "            # update on the ppmi_matrix\n",
    "            ppmi_matrix[row, col] = max(0, PMI)\n",
    "    if verbose:\n",
    "        print(\"\\r                                            \")\n",
    "    return ppmi_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating PPMI maxtrix for window size 2\n",
      "                                            \n",
      "Calculating PPMI maxtrix for window size 5\n",
      "                                            \n",
      "Calculating PPMI maxtrix for window size 10\n",
      "                                            \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# print(\"Calculating PPMI maxtrix for window size\", 2)\n",
    "# w2_ppmi_mat = calculate_ppmi_matrix(w2coocurence_mat)\n",
    "# print(\"Calculating PPMI maxtrix for window size\", 5)\n",
    "# w5_ppmi_mat = calculate_ppmi_matrix(w5coocurence_mat)\n",
    "# print(\"Calculating PPMI maxtrix for window size\", 10)\n",
    "# w10_ppmi_mat = calculate_ppmi_matrix(w10coocurence_mat)\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save PPMI matrix\n",
    "\"\"\"\n",
    "# scipy.sparse.save_npz(\"data/w2_ppmi_mat.npz\", scipy.sparse.coo_matrix(w2_ppmi_mat) )\n",
    "# scipy.sparse.save_npz(\"data/w5_ppmi_mat.npz\", scipy.sparse.coo_matrix(w5_ppmi_mat) )\n",
    "# scipy.sparse.save_npz(\"data/w10_ppmi_mat.npz\", scipy.sparse.coo_matrix(w10_ppmi_mat) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load PPMI matrix back\n",
    "\"\"\"\n",
    "# w2_ppmi_mat = scipy.sparse.load_npz(\"data/w2_ppmi_mat.npz\")\n",
    "# w5_ppmi_mat = scipy.sparse.load_npz(\"data/w5_ppmi_mat.npz\")\n",
    "# w10_ppmi_mat = scipy.sparse.load_npz(\"data/w10_ppmi_mat.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_decomposite(matrix, dimension):\n",
    "    \"\"\"\n",
    "    Decomposite the input matrix and form the word matrix and context matrix\n",
    "    \n",
    "    :param matrix: matrix to be decomposed\n",
    "    :param dimension: specify the number of dimension for word matrix\n",
    "    \n",
    "    :return: W, C. The word matrix and context matrix with each row representing a vector\n",
    "    \"\"\"\n",
    "    U, S, Vt = scipy.sparse.linalg.svds(matrix, k = 100)\n",
    "    sqrtS = np.sqrt(np.diag(S))\n",
    "    W = np.dot(U, sqrtS)\n",
    "    C = np.dot(Vt.T, sqrtS)\n",
    "    return W, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_svd_model_tofile(word_matrix, token_to_index, filename):\n",
    "    \"\"\"\n",
    "    Write the word matrix to file in order to evaluate\n",
    "    \n",
    "    :param word_matrix: the word matrix to be written to disk\n",
    "    :param token_to_index: dict, mapping token to index\n",
    "    :param filename: a string that specify the file to be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        for k in token_to_index:\n",
    "            vector = word_matrix[token_to_index[k], :]\n",
    "            # write word first\n",
    "            f.write(f\"{k} \")\n",
    "            # write values\n",
    "            for val in vector:\n",
    "                f.write(f\"{val} \")\n",
    "            f.write(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_svd_model_tofile(verbose = True):\n",
    "    \"\"\"\n",
    "    Calculating the the 9 SVD models and write them to txt file\n",
    "    \"\"\"\n",
    "    windows = (2,5,10)\n",
    "    dimensions = (100,300,1000)\n",
    "    for w in windows:\n",
    "        ppmi_mat = scipy.sparse.load_npz(f\"data/w{w}_ppmi_mat.npz\")\n",
    "        for d in dimensions:\n",
    "            filename = f\"model/w{w}s{d}-svd.txt\"\n",
    "            W, C = svd_decomposite(ppmi_mat, d)\n",
    "            if verbose:\n",
    "                print(f\"Writing {filename}...\")\n",
    "            write_svd_model_tofile(W, token_to_index, filename)\n",
    "    if verbose:\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/w2s100-svd.txt...\n",
      "Writing model/w2s300-svd.txt...\n",
      "Writing model/w2s1000-svd.txt...\n",
      "Writing model/w5s100-svd.txt...\n",
      "Writing model/w5s300-svd.txt...\n",
      "Writing model/w5s1000-svd.txt...\n",
      "Writing model/w10s100-svd.txt...\n",
      "Writing model/w10s300-svd.txt...\n",
      "Writing model/w10s1000-svd.txt...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "write_all_svd_model_tofile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_svd_models(verbose = True):\n",
    "    \"\"\"\n",
    "    Evaluating svd models and return all results in a dict\n",
    "    \"\"\"\n",
    "    windows = (2,5,10)\n",
    "    dimensions = (100,300,1000)\n",
    "    \n",
    "    evaluation_results = {}\n",
    "    for w in windows:\n",
    "        for d in dimensions:\n",
    "                key = f\"svd-w{w}d{d}\"\n",
    "                model_output_filename = f\"model/w{w}s{d}-svd.txt\"\n",
    "                if verbose:\n",
    "                    print(f\"Evaluating model {key}\")\n",
    "                evaluation_results[key] = evaluate.evaluate_models([model_output_filename], verbose=False)\n",
    "    if verbose:\n",
    "        print(\"Done!\")\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model svd-w2d100\n",
      "Evaluating model svd-w2d300\n",
      "Evaluating model svd-w2d1000\n",
      "Evaluating model svd-w5d100\n",
      "Evaluating model svd-w5d300\n",
      "Evaluating model svd-w5d1000\n",
      "Evaluating model svd-w10d100\n",
      "Evaluating model svd-w10d300\n",
      "Evaluating model svd-w10d1000\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# evaluate.evaluate_models([\"model/w2s100-svd.txt\"])\n",
    "svd_eval_results = eval_svd_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Model:svd-w2d100\n",
      "        WordSIM: -0.0623046117493807\t MSR: 0.6382608695652174\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w2d300\n",
      "        WordSIM: -0.0623046117493807\t MSR: 0.6382608695652174\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w2d1000\n",
      "        WordSIM: -0.0623046117493807\t MSR: 0.6382608695652174\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w5d100\n",
      "        WordSIM: -0.0035977035455661897\t MSR: 0.6353623188405797\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w5d300\n",
      "        WordSIM: -0.0035977035455661897\t MSR: 0.6353623188405797\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w5d1000\n",
      "        WordSIM: -0.0035977035455661897\t MSR: 0.6353623188405797\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w10d100\n",
      "        WordSIM: -0.006722224186856704\t MSR: 0.6342028985507246\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w10d300\n",
      "        WordSIM: -0.006722224186856704\t MSR: 0.6342028985507246\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n",
      "\n",
      "        Model:svd-w10d1000\n",
      "        WordSIM: -0.006722224186856704\t MSR: 0.6342028985507246\n",
      "        BAT1: 0.0\t BAT2: 0.0\t, BAT3: 0.0\n",
      "        ==============================================\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print_eval_results(svd_eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
